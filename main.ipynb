{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.dummy import DummyClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the data using pandas\n",
    "df = pd.read_csv('./Dataset/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_code</th>\n",
       "      <th>target</th>\n",
       "      <th>var_0</th>\n",
       "      <th>var_1</th>\n",
       "      <th>var_2</th>\n",
       "      <th>var_3</th>\n",
       "      <th>var_4</th>\n",
       "      <th>var_5</th>\n",
       "      <th>var_6</th>\n",
       "      <th>var_7</th>\n",
       "      <th>...</th>\n",
       "      <th>var_190</th>\n",
       "      <th>var_191</th>\n",
       "      <th>var_192</th>\n",
       "      <th>var_193</th>\n",
       "      <th>var_194</th>\n",
       "      <th>var_195</th>\n",
       "      <th>var_196</th>\n",
       "      <th>var_197</th>\n",
       "      <th>var_198</th>\n",
       "      <th>var_199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.9255</td>\n",
       "      <td>-6.7863</td>\n",
       "      <td>11.9081</td>\n",
       "      <td>5.0930</td>\n",
       "      <td>11.4607</td>\n",
       "      <td>-9.2834</td>\n",
       "      <td>5.1187</td>\n",
       "      <td>18.6266</td>\n",
       "      <td>...</td>\n",
       "      <td>4.4354</td>\n",
       "      <td>3.9642</td>\n",
       "      <td>3.1364</td>\n",
       "      <td>1.6910</td>\n",
       "      <td>18.5227</td>\n",
       "      <td>-2.3978</td>\n",
       "      <td>7.8784</td>\n",
       "      <td>8.5635</td>\n",
       "      <td>12.7803</td>\n",
       "      <td>-1.0914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_1</td>\n",
       "      <td>0</td>\n",
       "      <td>11.5006</td>\n",
       "      <td>-4.1473</td>\n",
       "      <td>13.8588</td>\n",
       "      <td>5.3890</td>\n",
       "      <td>12.3622</td>\n",
       "      <td>7.0433</td>\n",
       "      <td>5.6208</td>\n",
       "      <td>16.5338</td>\n",
       "      <td>...</td>\n",
       "      <td>7.6421</td>\n",
       "      <td>7.7214</td>\n",
       "      <td>2.5837</td>\n",
       "      <td>10.9516</td>\n",
       "      <td>15.4305</td>\n",
       "      <td>2.0339</td>\n",
       "      <td>8.1267</td>\n",
       "      <td>8.7889</td>\n",
       "      <td>18.3560</td>\n",
       "      <td>1.9518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_2</td>\n",
       "      <td>0</td>\n",
       "      <td>8.6093</td>\n",
       "      <td>-2.7457</td>\n",
       "      <td>12.0805</td>\n",
       "      <td>7.8928</td>\n",
       "      <td>10.5825</td>\n",
       "      <td>-9.0837</td>\n",
       "      <td>6.9427</td>\n",
       "      <td>14.6155</td>\n",
       "      <td>...</td>\n",
       "      <td>2.9057</td>\n",
       "      <td>9.7905</td>\n",
       "      <td>1.6704</td>\n",
       "      <td>1.6858</td>\n",
       "      <td>21.6042</td>\n",
       "      <td>3.1417</td>\n",
       "      <td>-6.5213</td>\n",
       "      <td>8.2675</td>\n",
       "      <td>14.7222</td>\n",
       "      <td>0.3965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train_3</td>\n",
       "      <td>0</td>\n",
       "      <td>11.0604</td>\n",
       "      <td>-2.1518</td>\n",
       "      <td>8.9522</td>\n",
       "      <td>7.1957</td>\n",
       "      <td>12.5846</td>\n",
       "      <td>-1.8361</td>\n",
       "      <td>5.8428</td>\n",
       "      <td>14.9250</td>\n",
       "      <td>...</td>\n",
       "      <td>4.4666</td>\n",
       "      <td>4.7433</td>\n",
       "      <td>0.7178</td>\n",
       "      <td>1.4214</td>\n",
       "      <td>23.0347</td>\n",
       "      <td>-1.2706</td>\n",
       "      <td>-2.9275</td>\n",
       "      <td>10.2922</td>\n",
       "      <td>17.9697</td>\n",
       "      <td>-8.9996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_4</td>\n",
       "      <td>0</td>\n",
       "      <td>9.8369</td>\n",
       "      <td>-1.4834</td>\n",
       "      <td>12.8746</td>\n",
       "      <td>6.6375</td>\n",
       "      <td>12.2772</td>\n",
       "      <td>2.4486</td>\n",
       "      <td>5.9405</td>\n",
       "      <td>19.2514</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.4905</td>\n",
       "      <td>9.5214</td>\n",
       "      <td>-0.1508</td>\n",
       "      <td>9.1942</td>\n",
       "      <td>13.2876</td>\n",
       "      <td>-1.5121</td>\n",
       "      <td>3.9267</td>\n",
       "      <td>9.5031</td>\n",
       "      <td>17.9974</td>\n",
       "      <td>-8.8104</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 202 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID_code  target    var_0   var_1    var_2   var_3    var_4   var_5   var_6  \\\n",
       "0  train_0       0   8.9255 -6.7863  11.9081  5.0930  11.4607 -9.2834  5.1187   \n",
       "1  train_1       0  11.5006 -4.1473  13.8588  5.3890  12.3622  7.0433  5.6208   \n",
       "2  train_2       0   8.6093 -2.7457  12.0805  7.8928  10.5825 -9.0837  6.9427   \n",
       "3  train_3       0  11.0604 -2.1518   8.9522  7.1957  12.5846 -1.8361  5.8428   \n",
       "4  train_4       0   9.8369 -1.4834  12.8746  6.6375  12.2772  2.4486  5.9405   \n",
       "\n",
       "     var_7  ...  var_190  var_191  var_192  var_193  var_194  var_195  \\\n",
       "0  18.6266  ...   4.4354   3.9642   3.1364   1.6910  18.5227  -2.3978   \n",
       "1  16.5338  ...   7.6421   7.7214   2.5837  10.9516  15.4305   2.0339   \n",
       "2  14.6155  ...   2.9057   9.7905   1.6704   1.6858  21.6042   3.1417   \n",
       "3  14.9250  ...   4.4666   4.7433   0.7178   1.4214  23.0347  -1.2706   \n",
       "4  19.2514  ...  -1.4905   9.5214  -0.1508   9.1942  13.2876  -1.5121   \n",
       "\n",
       "   var_196  var_197  var_198  var_199  \n",
       "0   7.8784   8.5635  12.7803  -1.0914  \n",
       "1   8.1267   8.7889  18.3560   1.9518  \n",
       "2  -6.5213   8.2675  14.7222   0.3965  \n",
       "3  -2.9275  10.2922  17.9697  -8.9996  \n",
       "4   3.9267   9.5031  17.9974  -8.8104  \n",
       "\n",
       "[5 rows x 202 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 200000 entries, 0 to 199999\n",
      "Columns: 202 entries, ID_code to var_199\n",
      "dtypes: float64(200), int64(1), object(1)\n",
      "memory usage: 308.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_code</th>\n",
       "      <th>target</th>\n",
       "      <th>var_0</th>\n",
       "      <th>var_1</th>\n",
       "      <th>var_2</th>\n",
       "      <th>var_3</th>\n",
       "      <th>var_4</th>\n",
       "      <th>var_5</th>\n",
       "      <th>var_6</th>\n",
       "      <th>var_7</th>\n",
       "      <th>...</th>\n",
       "      <th>var_190</th>\n",
       "      <th>var_191</th>\n",
       "      <th>var_192</th>\n",
       "      <th>var_193</th>\n",
       "      <th>var_194</th>\n",
       "      <th>var_195</th>\n",
       "      <th>var_196</th>\n",
       "      <th>var_197</th>\n",
       "      <th>var_198</th>\n",
       "      <th>var_199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>200000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>200000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>train_0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.100490</td>\n",
       "      <td>10.679914</td>\n",
       "      <td>-1.627622</td>\n",
       "      <td>10.715192</td>\n",
       "      <td>6.796529</td>\n",
       "      <td>11.078333</td>\n",
       "      <td>-5.065317</td>\n",
       "      <td>5.408949</td>\n",
       "      <td>16.545850</td>\n",
       "      <td>...</td>\n",
       "      <td>3.234440</td>\n",
       "      <td>7.438408</td>\n",
       "      <td>1.927839</td>\n",
       "      <td>3.331774</td>\n",
       "      <td>17.993784</td>\n",
       "      <td>-0.142088</td>\n",
       "      <td>2.303335</td>\n",
       "      <td>8.908158</td>\n",
       "      <td>15.870720</td>\n",
       "      <td>-3.326537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.300653</td>\n",
       "      <td>3.040051</td>\n",
       "      <td>4.050044</td>\n",
       "      <td>2.640894</td>\n",
       "      <td>2.043319</td>\n",
       "      <td>1.623150</td>\n",
       "      <td>7.863267</td>\n",
       "      <td>0.866607</td>\n",
       "      <td>3.418076</td>\n",
       "      <td>...</td>\n",
       "      <td>4.559922</td>\n",
       "      <td>3.023272</td>\n",
       "      <td>1.478423</td>\n",
       "      <td>3.992030</td>\n",
       "      <td>3.135162</td>\n",
       "      <td>1.429372</td>\n",
       "      <td>5.454369</td>\n",
       "      <td>0.921625</td>\n",
       "      <td>3.010945</td>\n",
       "      <td>10.438015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.408400</td>\n",
       "      <td>-15.043400</td>\n",
       "      <td>2.117100</td>\n",
       "      <td>-0.040200</td>\n",
       "      <td>5.074800</td>\n",
       "      <td>-32.562600</td>\n",
       "      <td>2.347300</td>\n",
       "      <td>5.349700</td>\n",
       "      <td>...</td>\n",
       "      <td>-14.093300</td>\n",
       "      <td>-2.691700</td>\n",
       "      <td>-3.814500</td>\n",
       "      <td>-11.783400</td>\n",
       "      <td>8.694400</td>\n",
       "      <td>-5.261000</td>\n",
       "      <td>-14.209600</td>\n",
       "      <td>5.960600</td>\n",
       "      <td>6.299300</td>\n",
       "      <td>-38.852800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.453850</td>\n",
       "      <td>-4.740025</td>\n",
       "      <td>8.722475</td>\n",
       "      <td>5.254075</td>\n",
       "      <td>9.883175</td>\n",
       "      <td>-11.200350</td>\n",
       "      <td>4.767700</td>\n",
       "      <td>13.943800</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.058825</td>\n",
       "      <td>5.157400</td>\n",
       "      <td>0.889775</td>\n",
       "      <td>0.584600</td>\n",
       "      <td>15.629800</td>\n",
       "      <td>-1.170700</td>\n",
       "      <td>-1.946925</td>\n",
       "      <td>8.252800</td>\n",
       "      <td>13.829700</td>\n",
       "      <td>-11.208475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.524750</td>\n",
       "      <td>-1.608050</td>\n",
       "      <td>10.580000</td>\n",
       "      <td>6.825000</td>\n",
       "      <td>11.108250</td>\n",
       "      <td>-4.833150</td>\n",
       "      <td>5.385100</td>\n",
       "      <td>16.456800</td>\n",
       "      <td>...</td>\n",
       "      <td>3.203600</td>\n",
       "      <td>7.347750</td>\n",
       "      <td>1.901300</td>\n",
       "      <td>3.396350</td>\n",
       "      <td>17.957950</td>\n",
       "      <td>-0.172700</td>\n",
       "      <td>2.408900</td>\n",
       "      <td>8.888200</td>\n",
       "      <td>15.934050</td>\n",
       "      <td>-2.819550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.758200</td>\n",
       "      <td>1.358625</td>\n",
       "      <td>12.516700</td>\n",
       "      <td>8.324100</td>\n",
       "      <td>12.261125</td>\n",
       "      <td>0.924800</td>\n",
       "      <td>6.003000</td>\n",
       "      <td>19.102900</td>\n",
       "      <td>...</td>\n",
       "      <td>6.406200</td>\n",
       "      <td>9.512525</td>\n",
       "      <td>2.949500</td>\n",
       "      <td>6.205800</td>\n",
       "      <td>20.396525</td>\n",
       "      <td>0.829600</td>\n",
       "      <td>6.556725</td>\n",
       "      <td>9.593300</td>\n",
       "      <td>18.064725</td>\n",
       "      <td>4.836800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>20.315000</td>\n",
       "      <td>10.376800</td>\n",
       "      <td>19.353000</td>\n",
       "      <td>13.188300</td>\n",
       "      <td>16.671400</td>\n",
       "      <td>17.251600</td>\n",
       "      <td>8.447700</td>\n",
       "      <td>27.691800</td>\n",
       "      <td>...</td>\n",
       "      <td>18.440900</td>\n",
       "      <td>16.716500</td>\n",
       "      <td>8.402400</td>\n",
       "      <td>18.281800</td>\n",
       "      <td>27.928800</td>\n",
       "      <td>4.272900</td>\n",
       "      <td>18.321500</td>\n",
       "      <td>12.000400</td>\n",
       "      <td>26.079100</td>\n",
       "      <td>28.500700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11 rows × 202 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID_code         target          var_0          var_1          var_2  \\\n",
       "count    200000  200000.000000  200000.000000  200000.000000  200000.000000   \n",
       "unique   200000            NaN            NaN            NaN            NaN   \n",
       "top     train_0            NaN            NaN            NaN            NaN   \n",
       "freq          1            NaN            NaN            NaN            NaN   \n",
       "mean        NaN       0.100490      10.679914      -1.627622      10.715192   \n",
       "std         NaN       0.300653       3.040051       4.050044       2.640894   \n",
       "min         NaN       0.000000       0.408400     -15.043400       2.117100   \n",
       "25%         NaN       0.000000       8.453850      -4.740025       8.722475   \n",
       "50%         NaN       0.000000      10.524750      -1.608050      10.580000   \n",
       "75%         NaN       0.000000      12.758200       1.358625      12.516700   \n",
       "max         NaN       1.000000      20.315000      10.376800      19.353000   \n",
       "\n",
       "                var_3          var_4          var_5          var_6  \\\n",
       "count   200000.000000  200000.000000  200000.000000  200000.000000   \n",
       "unique            NaN            NaN            NaN            NaN   \n",
       "top               NaN            NaN            NaN            NaN   \n",
       "freq              NaN            NaN            NaN            NaN   \n",
       "mean         6.796529      11.078333      -5.065317       5.408949   \n",
       "std          2.043319       1.623150       7.863267       0.866607   \n",
       "min         -0.040200       5.074800     -32.562600       2.347300   \n",
       "25%          5.254075       9.883175     -11.200350       4.767700   \n",
       "50%          6.825000      11.108250      -4.833150       5.385100   \n",
       "75%          8.324100      12.261125       0.924800       6.003000   \n",
       "max         13.188300      16.671400      17.251600       8.447700   \n",
       "\n",
       "                var_7  ...        var_190        var_191        var_192  \\\n",
       "count   200000.000000  ...  200000.000000  200000.000000  200000.000000   \n",
       "unique            NaN  ...            NaN            NaN            NaN   \n",
       "top               NaN  ...            NaN            NaN            NaN   \n",
       "freq              NaN  ...            NaN            NaN            NaN   \n",
       "mean        16.545850  ...       3.234440       7.438408       1.927839   \n",
       "std          3.418076  ...       4.559922       3.023272       1.478423   \n",
       "min          5.349700  ...     -14.093300      -2.691700      -3.814500   \n",
       "25%         13.943800  ...      -0.058825       5.157400       0.889775   \n",
       "50%         16.456800  ...       3.203600       7.347750       1.901300   \n",
       "75%         19.102900  ...       6.406200       9.512525       2.949500   \n",
       "max         27.691800  ...      18.440900      16.716500       8.402400   \n",
       "\n",
       "              var_193        var_194        var_195        var_196  \\\n",
       "count   200000.000000  200000.000000  200000.000000  200000.000000   \n",
       "unique            NaN            NaN            NaN            NaN   \n",
       "top               NaN            NaN            NaN            NaN   \n",
       "freq              NaN            NaN            NaN            NaN   \n",
       "mean         3.331774      17.993784      -0.142088       2.303335   \n",
       "std          3.992030       3.135162       1.429372       5.454369   \n",
       "min        -11.783400       8.694400      -5.261000     -14.209600   \n",
       "25%          0.584600      15.629800      -1.170700      -1.946925   \n",
       "50%          3.396350      17.957950      -0.172700       2.408900   \n",
       "75%          6.205800      20.396525       0.829600       6.556725   \n",
       "max         18.281800      27.928800       4.272900      18.321500   \n",
       "\n",
       "              var_197        var_198        var_199  \n",
       "count   200000.000000  200000.000000  200000.000000  \n",
       "unique            NaN            NaN            NaN  \n",
       "top               NaN            NaN            NaN  \n",
       "freq              NaN            NaN            NaN  \n",
       "mean         8.908158      15.870720      -3.326537  \n",
       "std          0.921625       3.010945      10.438015  \n",
       "min          5.960600       6.299300     -38.852800  \n",
       "25%          8.252800      13.829700     -11.208475  \n",
       "50%          8.888200      15.934050      -2.819550  \n",
       "75%          9.593300      18.064725       4.836800  \n",
       "max         12.000400      26.079100      28.500700  \n",
       "\n",
       "[11 rows x 202 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df.columns: \n",
    "    nans = df[col].isna().sum()\n",
    "    if nans > 0:\n",
    "        print(f'{col} has {df[col].isna().mean() * 100:.2f}% null values')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['ID_code'], 1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_cols = [col for col in df.columns if df[col].dtype == 'object']; categorical_cols, len(categorical_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "sns.countplot(x='target', data=df)\n",
    "plt.title('Distribution of Target Variable')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split tha data into train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['ID_code', 'target'], axis=1)  \n",
    "y = df['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\peter\\miniconda3\\envs\\big_data_env\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_model = LogisticRegression()\n",
    "logistic_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.91005\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.99      0.95     35903\n",
      "           1       0.66      0.25      0.36      4097\n",
      "\n",
      "    accuracy                           0.91     40000\n",
      "   macro avg       0.79      0.62      0.66     40000\n",
      "weighted avg       0.89      0.91      0.89     40000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logistic_predictions = logistic_model.predict(X_test)\n",
    "logistic_accuracy = accuracy_score(y_test, logistic_predictions)\n",
    "print(\"Logistic Regression Accuracy:\", logistic_accuracy)\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, logistic_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model = RandomForestClassifier()\n",
    "rf_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 0.8976\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      1.00      0.95     35903\n",
      "           1       1.00      0.00      0.00      4097\n",
      "\n",
      "    accuracy                           0.90     40000\n",
      "   macro avg       0.95      0.50      0.47     40000\n",
      "weighted avg       0.91      0.90      0.85     40000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf_predictions = rf_model.predict(X_test)\n",
    "\n",
    "\n",
    "rf_accuracy = accuracy_score(y_test, rf_predictions)\n",
    "print(\"Random Forest Accuracy:\", rf_accuracy)\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, rf_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adaboost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "adaboost_clf = AdaBoostClassifier(n_estimators=50, learning_rate=0.1, random_state=42)\n",
    "adaboost_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost Accuracy: 0.897575\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      1.00      0.95     35903\n",
      "           1       0.00      0.00      0.00      4097\n",
      "\n",
      "    accuracy                           0.90     40000\n",
      "   macro avg       0.45      0.50      0.47     40000\n",
      "weighted avg       0.81      0.90      0.85     40000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\peter\\miniconda3\\envs\\big_data_env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\peter\\miniconda3\\envs\\big_data_env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\peter\\miniconda3\\envs\\big_data_env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Make predictions\n",
    "adaboost_prediction = adaboost_clf.predict(X_test)\n",
    "\n",
    "adaboost_accuracy = accuracy_score(y_test, adaboost_prediction)\n",
    "print(\"AdaBoost Accuracy:\", adaboost_accuracy)\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, adaboost_prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Accuracy: 0.912025\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.99      0.95     35903\n",
      "           1       0.71      0.24      0.36      4097\n",
      "\n",
      "    accuracy                           0.91     40000\n",
      "   macro avg       0.81      0.62      0.66     40000\n",
      "weighted avg       0.90      0.91      0.89     40000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xgb_model = xgb.XGBClassifier()\n",
    "xgb_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_predictions = xgb_model.predict(X_test)\n",
    "\n",
    "xgb_accuracy = accuracy_score(y_test, xgb_predictions)\n",
    "print(\"XGBoost Accuracy:\", xgb_accuracy)\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, xgb_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an SVM classifier\n",
    "clf = svm.SVC()\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy: 0.897575\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      1.00      0.95     35903\n",
      "           1       0.00      0.00      0.00      4097\n",
      "\n",
      "    accuracy                           0.90     40000\n",
      "   macro avg       0.45      0.50      0.47     40000\n",
      "weighted avg       0.81      0.90      0.85     40000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\peter\\miniconda3\\envs\\big_data_env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\peter\\miniconda3\\envs\\big_data_env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\peter\\miniconda3\\envs\\big_data_env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "clf_predictions = clf.predict(X_test)\n",
    "\n",
    "clf_accuracy = accuracy_score(y_test, clf_predictions)\n",
    "print(\"SVM Accuracy:\", clf_accuracy)\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, clf_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### zeroR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DummyClassifier(strategy=&#x27;most_frequent&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DummyClassifier</label><div class=\"sk-toggleable__content\"><pre>DummyClassifier(strategy=&#x27;most_frequent&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DummyClassifier(strategy='most_frequent')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a ZeroR classifier (always predicts the majority class)\n",
    "zero_r_classifier = DummyClassifier(strategy=\"most_frequent\")\n",
    "zero_r_classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ZeroR Accuracy: 0.897575\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      1.00      0.95     35903\n",
      "           1       0.00      0.00      0.00      4097\n",
      "\n",
      "    accuracy                           0.90     40000\n",
      "   macro avg       0.45      0.50      0.47     40000\n",
      "weighted avg       0.81      0.90      0.85     40000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\peter\\miniconda3\\envs\\big_data_env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\peter\\miniconda3\\envs\\big_data_env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\peter\\miniconda3\\envs\\big_data_env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Make predictions\n",
    "zero_r_pred = zero_r_classifier.predict(X_test)\n",
    "\n",
    "zero_r_accuracy = accuracy_score(y_test, zero_r_pred)\n",
    "print(\"ZeroR Accuracy:\", zero_r_accuracy)\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, zero_r_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "big_data_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
